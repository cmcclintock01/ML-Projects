{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Assignment 5 - Classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## About the dataset\n",
    "The data set you will be using is the cars_base data set from before\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Get the DataSet and clean it\n",
    "\n",
    "1. Read the cars_base.csv file into a data frame\n",
    "\n",
    "1. Display the info\n",
    "\n",
    "1. Clean the data set as per last time.\n",
    "\n",
    "1. Create a \"mpg_grade\" feature that is a category based on \"mpg\". Base the mpg_grade so that 0 is the first quartile, 1 is the second quartile, 2 is the third quartile, and 3 is the fourth quartile.  (You can get the quartile values from the describe method of a data frame.) \n",
    "\n",
    "1. Split into train and test sets (70% and 30%)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              mpg   cylinders  displacement  horsepower       weight  \\\n",
      "count  398.000000  398.000000    398.000000  398.000000   398.000000   \n",
      "mean    23.514573    5.454774    193.425879  104.469388  2970.424623   \n",
      "std      7.815984    1.701004    104.269838   38.199187   846.841774   \n",
      "min      9.000000    3.000000     68.000000   46.000000  1613.000000   \n",
      "25%     17.500000    4.000000    104.250000   76.000000  2223.750000   \n",
      "50%     23.000000    4.000000    148.500000   95.000000  2803.500000   \n",
      "75%     29.000000    8.000000    262.000000  125.000000  3608.000000   \n",
      "max     46.600000    8.000000    455.000000  230.000000  5140.000000   \n",
      "\n",
      "       acceleration  model year      origin   mpg_grade  \n",
      "count    398.000000  398.000000  398.000000  398.000000  \n",
      "mean      15.568090   76.010050    1.572864    1.462312  \n",
      "std        2.757689    3.697627    0.802055    1.123299  \n",
      "min        8.000000   70.000000    1.000000    0.000000  \n",
      "25%       13.825000   73.000000    1.000000    0.000000  \n",
      "50%       15.500000   76.000000    1.000000    1.000000  \n",
      "75%       17.175000   79.000000    2.000000    2.000000  \n",
      "max       24.800000   82.000000    3.000000    3.000000  \n",
      "278 120\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def mpg_grade(x):\n",
    "    if x <= 17.5:\n",
    "        return 0\n",
    "    elif x > 17.5 and x <= 23:\n",
    "        return 1\n",
    "    elif x > 23 and x <= 29:\n",
    "        return 2\n",
    "    else:\n",
    "        return 3\n",
    "\n",
    "data = pd.read_csv(\"cars_base.csv\")\n",
    "hp_mean = data['horsepower'].mean()\n",
    "\n",
    "data.fillna(value = hp_mean, inplace=True)\n",
    "\n",
    "data['mpg_grade'] = data['mpg'].apply(mpg_grade)\n",
    "print(data.describe())\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_set, test_set = train_test_split(data, test_size = 0.3, random_state=42)\n",
    "print(len(train_set), len(test_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2 - Building the decision tree\n",
    "Train a decision tree using \n",
    "X - Uses your choice of at least 4 features (Not including mpg, or mpg_grade)\n",
    "y - Classification is \"mpg_grade\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "DecisionTreeClassifier()"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "X = train_set[['horsepower', 'acceleration', 'weight', 'cylinders']]\n",
    "Y = train_set['mpg_grade']\n",
    "\n",
    "tc = DecisionTreeClassifier()\n",
    "tc.fit(X, Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3 - Evaluation  (Confusion Matrix)\n",
    "Create and display the confusion matrix for the training set.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[74  0  0  0]\n",
      " [ 0 73  0  0]\n",
      " [ 0  0 61  0]\n",
      " [ 0  0  0 70]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "y_pred = tc.predict(X)\n",
    "matrix = confusion_matrix(Y, y_pred)\n",
    "print(matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your comments here:\n",
    "This looks to be a perfect confusion matrix from the jump. There may be a level of overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4 - Evaluation (Other metrics)\n",
    "Compute Accuracy, Precision, Sensitivity and F1 scores from the training data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy  1.0\n",
      "Sensitivity  1.0\n",
      "Precision  1.0\n",
      "F1  1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "print(\"Accuracy \", accuracy_score(Y, y_pred))\n",
    "print(\"Sensitivity \", recall_score(Y, y_pred, average='weighted'))\n",
    "print(\"Precision \", precision_score(Y, y_pred, average='weighted'))\n",
    "print(\"F1 \", f1_score(Y, y_pred, average='weighted'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5 - Displaying the decision tree\n",
    "Export the decision tree to \"salary.dot\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import export_graphviz\n",
    "\n",
    "export_graphviz(tc, out_file='salary.dot')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Look at the Dot file and answer the following questions:\n",
    "1. How many nodes are in the tree?\n",
    "There is 152 nodes.\n",
    "1. What is the first split\n",
    "[74, 73, 61, 70]\n",
    "1. How many leaf nodes are in the tree?  (They will have a lable that just gives a GINI impurity value.)\n",
    "There are 77 leaf nodes\n",
    "1. What would you suggest to prevent overfitting?\n",
    "Doing a K-fold cross validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bonus - Create a .eps or .png file.\n",
    "\n",
    "To install graphviz, check out https://www.graphviz.org\n",
    "You will probably need to compile and install graphviz, though there may be an executable version you can download.  \n",
    "\n",
    "Once you have the dot file, you can render by command line:\n",
    "\n",
    "```dot -Tps input.dot > output.eps```\n",
    "\n",
    "```dot -Tpng input.dot > output.png```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 6 (Base Line) : Cross Validate Using A Decision Tree Classifier \n",
    "\n",
    "Do a 5 fold cross validation on the entire data set where\n",
    "\n",
    "X - Uses your choice of at least 4 features (Not including mpg or mpg_grade)\n",
    "y - Classification is \"mpg_grade\"\n",
    "\n",
    "Compute and display the confusion matrix, Accuracy, and F1 score for each fold\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross validation accuracies are:  [0.7142857142857143, 0.7678571428571429, 0.6428571428571429, 0.7090909090909091, 0.6]\n",
      "Cross validation f1 are:  [0.7123015873015872, 0.7509711219013545, 0.6265371533228675, 0.7126143922596251, 0.5950630351884272]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "validation_accuracy = []\n",
    "validation_f1 = []\n",
    "fold_and_validate = KFold(n_splits=5, shuffle=True, random_state=145)\n",
    "for train_set_ind, valid_set_ind in fold_and_validate.split(X):\n",
    "    t_set = X.iloc[train_set_ind]\n",
    "    t_tar = Y.iloc[train_set_ind]\n",
    "    \n",
    "    cv_dt = DecisionTreeClassifier()\n",
    "    cv_dt.fit(t_set, t_tar)\n",
    "    \n",
    "    xval = X.iloc[valid_set_ind]\n",
    "    y_true = Y.iloc[valid_set_ind]\n",
    "    cvy_pred = cv_dt.predict(xval)\n",
    "    accuracy = accuracy_score(y_true, cvy_pred)\n",
    "    f1 = f1_score(y_true, cvy_pred, average='weighted')\n",
    "    validation_accuracy.append(accuracy)\n",
    "    validation_f1.append(f1)\n",
    "    \n",
    "print(\"Cross validation accuracies are: \", validation_accuracy)\n",
    "print(\"Cross validation f1 are: \", validation_f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 7 - Train and test SVM\n",
    "Train a linear SVC on the train set.  Use the same features and target as per the baseline.\n",
    "\n",
    "1. Use the train set to predict the targets, then compute and display the confusion matrix, Accuracy and F1 score.\n",
    "\n",
    "1. Use the test set to predict the targets, then compute and display the confusion matrix, Accuracy and F1 score.\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[62 12  0  0]\n",
      " [ 6 54 10  3]\n",
      " [ 1 10 29 21]\n",
      " [ 0  5  9 56]]\n",
      "Accuracy  0.7230215827338129\n",
      "f1  0.7197410777900515\n",
      "[[28  2  0  0]\n",
      " [ 3 16 10  1]\n",
      " [ 0  1 23  9]\n",
      " [ 0  0  4 23]]\n",
      "Accuracy  0.75\n",
      "f1  0.7459877885580463\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "sc = SVC(kernel='linear')\n",
    "sc.fit(X,Y)\n",
    "y_pred = sc.predict(X)\n",
    "print(confusion_matrix(Y, y_pred))\n",
    "print(\"Accuracy \", accuracy_score(Y, y_pred))\n",
    "print(\"f1 \", f1_score(Y, y_pred, average='weighted'))\n",
    "\n",
    "\n",
    "test_X = test_set[['horsepower', 'acceleration', 'weight', 'cylinders']]\n",
    "test_Y = test_set['mpg_grade']\n",
    "sc.fit(test_X, test_Y)\n",
    "test_y_pred = sc.predict(test_X)\n",
    "print(confusion_matrix(test_Y, test_y_pred))\n",
    "print(\"Accuracy \", accuracy_score(test_Y, test_y_pred))\n",
    "print(\"f1 \", f1_score(test_Y, test_y_pred, average='weighted'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 8 - Cross validate linear SVM\n",
    "Do a 5 fold cross validation on a linear SVC model using the same features and target as in the Base Line. Compute and display the confusion matrix, accuracy, and F1 score. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross validation confusion matrices are:  [array([[10,  2,  0,  0],\n",
      "       [ 2, 11,  3,  4],\n",
      "       [ 1,  2,  1,  7],\n",
      "       [ 0,  0,  2, 11]], dtype=int64), array([[10,  7,  0,  0],\n",
      "       [ 1,  9,  2,  0],\n",
      "       [ 0,  3,  1,  5],\n",
      "       [ 0,  0,  2, 16]], dtype=int64), array([[15,  1,  0,  0],\n",
      "       [ 2,  9,  0,  1],\n",
      "       [ 0,  8,  3,  3],\n",
      "       [ 0,  3,  1, 10]], dtype=int64), array([[12,  1,  0,  0],\n",
      "       [ 3, 13,  1,  2],\n",
      "       [ 0,  1,  4,  6],\n",
      "       [ 0,  1,  0, 11]], dtype=int64), array([[14,  2,  0,  0],\n",
      "       [ 0,  7,  1,  2],\n",
      "       [ 0,  5,  1, 10],\n",
      "       [ 0,  2,  1, 10]], dtype=int64)]\n",
      "Cross validation accuracies are:  [0.5892857142857143, 0.6428571428571429, 0.6607142857142857, 0.7272727272727273, 0.5818181818181818]\n",
      "Cross validation f1 are:  [0.5649459783913565, 0.6279561452372512, 0.6385281385281385, 0.7140594888981986, 0.5351041940515624]\n"
     ]
    }
   ],
   "source": [
    "validation_cm = []\n",
    "validation_accuracy = []\n",
    "validation_f1 = []\n",
    "fold_and_validate = KFold(n_splits=5, shuffle=True, random_state=145)\n",
    "for train_set_ind, valid_set_ind in fold_and_validate.split(X):\n",
    "    t_set = X.iloc[train_set_ind]\n",
    "    t_tar = Y.iloc[train_set_ind]\n",
    "    \n",
    "    cv_svc = SVC()\n",
    "    cv_svc.fit(t_set, t_tar)\n",
    "    \n",
    "    xval = X.iloc[valid_set_ind]\n",
    "    y_true = Y.iloc[valid_set_ind]\n",
    "    cvy_pred = cv_svc.predict(xval)\n",
    "    matrix = confusion_matrix(y_true, cvy_pred)\n",
    "    accuracy = accuracy_score(y_true, cvy_pred)\n",
    "    f1 = f1_score(y_true, cvy_pred, average='weighted')\n",
    "    validation_cm.append(matrix)\n",
    "    validation_accuracy.append(accuracy)\n",
    "    validation_f1.append(f1)\n",
    "    \n",
    "print(\"Cross validation confusion matrices are: \", validation_cm)\n",
    "print(\"Cross validation accuracies are: \", validation_accuracy)\n",
    "print(\"Cross validation f1 are: \", validation_f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare the results.\n",
    "1. Based on Part 1, did the SVC model overfit the data?\n",
    "1. Compare the results of the test set to the cross validation results.\n",
    "1. How did the linear SVC model perform compared to the decision tree classifier?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. No the SVC model did not but the original model did.\n",
    "2. The test set did a lot better than the cross validation. It had higher f1 and accuracy.\n",
    "3. The model did not do as well but there was a high chance of overfitting in the decision tree classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 9 - Train and test SVM\n",
    "Train a rbf SVC on the train set and then compute and display metrics for the train and test sets as in the BaseLine\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[61 13  0  0]\n",
      " [ 8 51  6  8]\n",
      " [ 1 15 16 29]\n",
      " [ 0  6  6 58]]\n",
      "Accuracy  0.6690647482014388\n",
      "f1  0.6509558712399626\n",
      "[[26  4  0  0]\n",
      " [ 3 16 11  0]\n",
      " [ 0  3 22  8]\n",
      " [ 0  0  6 21]]\n",
      "Accuracy  0.7083333333333334\n",
      "f1  0.7080879348328182\n"
     ]
    }
   ],
   "source": [
    "sc = SVC(kernel='rbf')\n",
    "sc.fit(X,Y)\n",
    "y_pred = sc.predict(X)\n",
    "print(confusion_matrix(Y, y_pred))\n",
    "print(\"Accuracy \", accuracy_score(Y, y_pred))\n",
    "print(\"f1 \", f1_score(Y, y_pred, average='weighted'))\n",
    "\n",
    "\n",
    "sc.fit(test_X, test_Y)\n",
    "test_y_pred = sc.predict(test_X)\n",
    "print(confusion_matrix(test_Y, test_y_pred))\n",
    "print(\"Accuracy \", accuracy_score(test_Y, test_y_pred))\n",
    "print(\"f1 \", f1_score(test_Y, test_y_pred, average='weighted'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 10 - Cross validate RBF SVM\n",
    "Do a 5 fold cross validation on a SVC model with an RBF kernel using the same features and target as in the BaseLine. Compute and display metrics as before.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross validation confusion matrices are:  [array([[10,  2,  0,  0],\n",
      "       [ 2, 11,  3,  4],\n",
      "       [ 1,  2,  1,  7],\n",
      "       [ 0,  0,  2, 11]], dtype=int64), array([[10,  7,  0,  0],\n",
      "       [ 1,  9,  2,  0],\n",
      "       [ 0,  3,  1,  5],\n",
      "       [ 0,  0,  2, 16]], dtype=int64), array([[15,  1,  0,  0],\n",
      "       [ 2,  9,  0,  1],\n",
      "       [ 0,  8,  3,  3],\n",
      "       [ 0,  3,  1, 10]], dtype=int64), array([[12,  1,  0,  0],\n",
      "       [ 3, 13,  1,  2],\n",
      "       [ 0,  1,  4,  6],\n",
      "       [ 0,  1,  0, 11]], dtype=int64), array([[14,  2,  0,  0],\n",
      "       [ 0,  7,  1,  2],\n",
      "       [ 0,  5,  1, 10],\n",
      "       [ 0,  2,  1, 10]], dtype=int64)]\n",
      "Cross validation accuracies are:  [0.5892857142857143, 0.6428571428571429, 0.6607142857142857, 0.7272727272727273, 0.5818181818181818]\n",
      "Cross validation f1 are:  [0.5649459783913565, 0.6279561452372512, 0.6385281385281385, 0.7140594888981986, 0.5351041940515624]\n"
     ]
    }
   ],
   "source": [
    "validation_cm = []\n",
    "validation_accuracy = []\n",
    "validation_f1 = []\n",
    "fold_and_validate = KFold(n_splits=5, shuffle=True, random_state=145)\n",
    "for train_set_ind, valid_set_ind in fold_and_validate.split(X):\n",
    "    t_set = X.iloc[train_set_ind]\n",
    "    t_tar = Y.iloc[train_set_ind]\n",
    "    \n",
    "    cv_svc = SVC(kernel='rbf')\n",
    "    cv_svc.fit(t_set, t_tar)\n",
    "    \n",
    "    xval = X.iloc[valid_set_ind]\n",
    "    y_true = Y.iloc[valid_set_ind]\n",
    "    cvy_pred = cv_svc.predict(xval)\n",
    "    matrix = confusion_matrix(y_true, cvy_pred)\n",
    "    accuracy = accuracy_score(y_true, cvy_pred)\n",
    "    f1 = f1_score(y_true, cvy_pred, average='weighted')\n",
    "    validation_cm.append(matrix)\n",
    "    validation_accuracy.append(accuracy)\n",
    "    validation_f1.append(f1)\n",
    "    \n",
    "print(\"Cross validation confusion matrices are: \", validation_cm)\n",
    "print(\"Cross validation accuracies are: \", validation_accuracy)\n",
    "print(\"Cross validation f1 are: \", validation_f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Your comparison with previous results here:\n",
    "This model did not do as well as the past models. Even the svm linear model had better data when looking at the whole train_set. When the cross validations are completed they did exactly the same as the SVM linear."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 11 - Train and test SVM\n",
    "Train a polynomial SVC on the train set and then compute and display metrics for the train and test sets (as in the BaseLine).\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[62 12  0  0]\n",
      " [ 9 49  6  9]\n",
      " [ 1 11 18 31]\n",
      " [ 0  5  6 59]]\n",
      "Accuracy  0.6762589928057554\n",
      "f1  0.6602527200671403\n",
      "[[26  4  0  0]\n",
      " [ 2 15 12  1]\n",
      " [ 0  3 14 16]\n",
      " [ 0  0  3 24]]\n",
      "Accuracy  0.6583333333333333\n",
      "f1  0.6513857780641136\n"
     ]
    }
   ],
   "source": [
    "sc = SVC(kernel='poly')\n",
    "sc.fit(X,Y)\n",
    "y_pred = sc.predict(X)\n",
    "print(confusion_matrix(Y, y_pred))\n",
    "print(\"Accuracy \", accuracy_score(Y, y_pred))\n",
    "print(\"f1 \", f1_score(Y, y_pred, average='weighted'))\n",
    "\n",
    "\n",
    "sc.fit(test_X, test_Y)\n",
    "test_y_pred = sc.predict(test_X)\n",
    "print(confusion_matrix(test_Y, test_y_pred))\n",
    "print(\"Accuracy \", accuracy_score(test_Y, test_y_pred))\n",
    "print(\"f1 \", f1_score(test_Y, test_y_pred, average='weighted'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 12 - Cross validate polynomial SVM\n",
    "Do a 5 fold cross validation on a SVC model with an Polynomial kernel using the same features and target as in the BaseLine. Compute and display metrics as before.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross validation confusion matrices are:  [array([[10,  2,  0,  0],\n",
      "       [ 2, 11,  3,  4],\n",
      "       [ 1,  2,  1,  7],\n",
      "       [ 0,  0,  2, 11]], dtype=int64), array([[10,  7,  0,  0],\n",
      "       [ 1,  8,  3,  0],\n",
      "       [ 0,  2,  2,  5],\n",
      "       [ 0,  0,  1, 17]], dtype=int64), array([[15,  1,  0,  0],\n",
      "       [ 2,  9,  0,  1],\n",
      "       [ 0,  5,  6,  3],\n",
      "       [ 0,  3,  1, 10]], dtype=int64), array([[12,  1,  0,  0],\n",
      "       [ 3, 11,  3,  2],\n",
      "       [ 0,  1,  4,  6],\n",
      "       [ 0,  1,  0, 11]], dtype=int64), array([[14,  2,  0,  0],\n",
      "       [ 0,  7,  1,  2],\n",
      "       [ 0,  2,  4, 10],\n",
      "       [ 0,  1,  2, 10]], dtype=int64)]\n",
      "Cross validation accuracies are:  [0.5892857142857143, 0.6607142857142857, 0.7142857142857143, 0.6909090909090909, 0.6363636363636364]\n",
      "Cross validation f1 are:  [0.5649459783913565, 0.6511347642505277, 0.7097402597402597, 0.6766280314667411, 0.6234683366699176]\n"
     ]
    }
   ],
   "source": [
    "validation_cm = []\n",
    "validation_accuracy = []\n",
    "validation_f1 = []\n",
    "fold_and_validate = KFold(n_splits=5, shuffle=True, random_state=145)\n",
    "for train_set_ind, valid_set_ind in fold_and_validate.split(X):\n",
    "    t_set = X.iloc[train_set_ind]\n",
    "    t_tar = Y.iloc[train_set_ind]\n",
    "    \n",
    "    cv_svc = SVC(kernel='poly')\n",
    "    cv_svc.fit(t_set, t_tar)\n",
    "    \n",
    "    xval = X.iloc[valid_set_ind]\n",
    "    y_true = Y.iloc[valid_set_ind]\n",
    "    cvy_pred = cv_svc.predict(xval)\n",
    "    matrix = confusion_matrix(y_true, cvy_pred)\n",
    "    accuracy = accuracy_score(y_true, cvy_pred)\n",
    "    f1 = f1_score(y_true, cvy_pred, average='weighted')\n",
    "    validation_cm.append(matrix)\n",
    "    validation_accuracy.append(accuracy)\n",
    "    validation_f1.append(f1)\n",
    "    \n",
    "print(\"Cross validation confusion matrices are: \", validation_cm)\n",
    "print(\"Cross validation accuracies are: \", validation_accuracy)\n",
    "print(\"Cross validation f1 are: \", validation_f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your comparison with previous results here: This model showed even less promise than the two before. The cross validation scores are all somewhat consistent in the .6 range and neither training set or test set confusion matrix did very well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 13 - Train and test SVM\n",
    "Train a sigmoid SVC on the train set and then compute and display metrics for the train and test sets (as in the BaseLine).\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 8  0  0 66]\n",
      " [57  0  0 16]\n",
      " [59  0  0  2]\n",
      " [70  0  0  0]]\n",
      "Accuracy  0.02877697841726619\n",
      "f1  0.015891764200579837\n",
      "[[ 0  0 30  0]\n",
      " [ 1  0 29  0]\n",
      " [16  0 17  0]\n",
      " [24  0  3  0]]\n",
      "Accuracy  0.14166666666666666\n",
      "f1  0.08348214285714287\n"
     ]
    }
   ],
   "source": [
    "sc = SVC(kernel='sigmoid')\n",
    "sc.fit(X,Y)\n",
    "y_pred = sc.predict(X)\n",
    "print(confusion_matrix(Y, y_pred))\n",
    "print(\"Accuracy \", accuracy_score(Y, y_pred))\n",
    "print(\"f1 \", f1_score(Y, y_pred, average='weighted'))\n",
    "\n",
    "\n",
    "sc.fit(test_X, test_Y)\n",
    "test_y_pred = sc.predict(test_X)\n",
    "print(confusion_matrix(test_Y, test_y_pred))\n",
    "print(\"Accuracy \", accuracy_score(test_Y, test_y_pred))\n",
    "print(\"f1 \", f1_score(test_Y, test_y_pred, average='weighted'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 14 - Cross validate sigmoid SVM\n",
    "Do a 5 fold cross validation on a SVC model with a signoid kernel using the same features and target as in the BaseLine. Compute and display metrics as before.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross validation confusion matrices are:  [array([[ 2,  0,  0, 10],\n",
      "       [18,  0,  0,  2],\n",
      "       [10,  0,  0,  1],\n",
      "       [13,  0,  0,  0]], dtype=int64), array([[ 7,  0,  0, 10],\n",
      "       [11,  0,  0,  1],\n",
      "       [ 9,  0,  0,  0],\n",
      "       [18,  0,  0,  0]], dtype=int64), array([[ 0,  0,  0, 16],\n",
      "       [ 8,  0,  0,  4],\n",
      "       [14,  0,  0,  0],\n",
      "       [14,  0,  0,  0]], dtype=int64), array([[ 1,  0,  0, 12],\n",
      "       [15,  0,  0,  4],\n",
      "       [11,  0,  0,  0],\n",
      "       [12,  0,  0,  0]], dtype=int64), array([[ 2,  0,  0, 14],\n",
      "       [ 6,  0,  0,  4],\n",
      "       [15,  0,  0,  1],\n",
      "       [13,  0,  0,  0]], dtype=int64)]\n",
      "Cross validation accuracies are:  [0.03571428571428571, 0.125, 0.0, 0.01818181818181818, 0.03636363636363636]\n",
      "Cross validation f1 are:  [0.015584415584415584, 0.06854838709677419, 0.0, 0.00909090909090909, 0.022377622377622374]\n"
     ]
    }
   ],
   "source": [
    "validation_cm = []\n",
    "validation_accuracy = []\n",
    "validation_f1 = []\n",
    "fold_and_validate = KFold(n_splits=5, shuffle=True, random_state=145)\n",
    "for train_set_ind, valid_set_ind in fold_and_validate.split(X):\n",
    "    t_set = X.iloc[train_set_ind]\n",
    "    t_tar = Y.iloc[train_set_ind]\n",
    "    \n",
    "    cv_svc = SVC(kernel='sigmoid')\n",
    "    cv_svc.fit(t_set, t_tar)\n",
    "    \n",
    "    xval = X.iloc[valid_set_ind]\n",
    "    y_true = Y.iloc[valid_set_ind]\n",
    "    cvy_pred = cv_svc.predict(xval)\n",
    "    matrix = confusion_matrix(y_true, cvy_pred)\n",
    "    accuracy = accuracy_score(y_true, cvy_pred)\n",
    "    f1 = f1_score(y_true, cvy_pred, average='weighted')\n",
    "    validation_cm.append(matrix)\n",
    "    validation_accuracy.append(accuracy)\n",
    "    validation_f1.append(f1)\n",
    "    \n",
    "print(\"Cross validation confusion matrices are: \", validation_cm)\n",
    "print(\"Cross validation accuracies are: \", validation_accuracy)\n",
    "print(\"Cross validation f1 are: \", validation_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your comparison with previous results here: This had the worst response out of any of the models. It has low accuracies and low f1 scores. The confusion matrix showed very little right."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Propose an explanation for the results that you found for the SVM with the different kernels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your explanation here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus\n",
    "1. Use a Stochastic Gradient Descent classifier and compare the performance.\n",
    "1. Use a Random Forrest classifier and compare the performance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
